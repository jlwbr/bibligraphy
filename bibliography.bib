@incollection{bagginiReneDescartesMeditations2002,
  title = {Ren\'e {{Descartes}}: {{Meditations}} on {{First Philosophy}} (1641)},
  shorttitle = {Ren\'e {{Descartes}}},
  booktitle = {Philosophy: {{Key Texts}}},
  author = {Baggini, Julian},
  editor = {Baggini, Julian},
  year = {2002},
  pages = {35--60},
  publisher = {{Palgrave Macmillan UK}},
  address = {{London}},
  doi = {10.1007/978-1-4039-1370-8_3},
  urldate = {2022-04-10},
  abstract = {Descartes's Meditations is one of the most important works in the rationalist tradition of philosophy. Rationalism is characterised by a belief that all the major problems of philosophy \textemdash{} and perhaps all the major intellectual problems of the world, full stop \textemdash{} can be answered by the application of rational thought alone.},
  isbn = {978-1-4039-1370-8},
  langid = {english},
  file = {C:\Users\joelw\Zotero\storage\GGLQG6B8\Baggini_2002_René Descartes.pdf}
}

@article{bratmanPlanningTheorySelfgovernance2017,
  title = {A Planning Theory of Self-Governance: Reply to {{Franklin}}},
  shorttitle = {A Planning Theory of Self-Governance},
  author = {Bratman, Michael E.},
  year = {2017},
  month = jan,
  journal = {Philosophical Explorations},
  volume = {20},
  number = {1},
  pages = {15--20},
  publisher = {{Routledge}},
  issn = {1386-9795},
  doi = {10.1080/13869795.2016.1269936},
  urldate = {2022-04-12},
  file = {C\:\\Users\\joelw\\Zotero\\storage\\GKRH7HCZ\\Bratman_2017_A planning theory of self-governance.pdf;C\:\\Users\\joelw\\Zotero\\storage\\HPX89N5F\\13869795.2016.html}
}

@book{bratmanSharedAgencyPlanning2014,
  title = {Shared {{Agency}}: {{A Planning Theory}} of {{Acting Together}}},
  shorttitle = {Shared {{Agency}}},
  author = {Bratman, Michael E.},
  year = {2014},
  publisher = {{Oxford University Press}},
  doi = {10.1093/acprof:oso/9780199897933.001.0001},
  abstract = {Human beings act together in characteristic ways; and these forms of shared activity matter to us a great deal. Think of friendship, singing duets, dancing together, and the joys of conversation. And think about the usefulness of conversation and of how we frequently manage to work together to achieve complex goals. This book seeks a framework for understanding these forms of sociality: What concepts are needed? In what do these forms of sociality consist? How are they related to individual agency? What norms are central to such sociality? How are these social norms related to norms that apply in the first instance to individual agency? These are questions about the conceptual, metaphysical, and normative foundations of our sociality. A conjecture of this book is that a rich account of individual planning agency facilitates the step to such sociality. There is independent reason\textemdash grounded in the organization of our temporally extended agency\textemdash to see planning structures as basic to our individual agency. Once these planning structures are on board, we can expect them to play central roles in our sociality. The planning theory of individual agency highlights distinctive roles and norms of intentions, understood as plan states. Appeal to these planning structures provides resources\textemdash conceptual, metaphysical, and normative\textemdash for an account of basic forms of sociality, including shared intention, and shared intentional and shared cooperative action. Shared agency emerges, both functionally and rationally, from structures of interconnected planning agency. This is a basic continuity between individual and social agency. And this is an aspect of the fecundity of planning structures, the idea that planning capacities ground a range of fundamental human practical capacities.},
  isbn = {978-0-19-989793-3},
  langid = {english},
  keywords = {continuity of shared agency with individual planning agency,fecundity of planning structures,planning agency,Shared agency,shared cooperative action,shared intention,shared intentional action,temporally extended agency}
}

@misc{canoAutomatingTextNaturalness2020,
  title = {Automating {{Text Naturalness Evaluation}} of {{NLG Systems}}},
  author = {{\c C}ano, Erion and Bojar, Ond{\v r}ej},
  year = {2020},
  month = jun,
  number = {arXiv:2006.13268},
  eprint = {2006.13268},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2006.13268},
  urldate = {2023-11-16},
  abstract = {Automatic methods and metrics that assess various quality criteria of automatically generated texts are important for developing NLG systems because they produce repeatable results and allow for a fast development cycle. We present here an attempt to automate the evaluation of text naturalness which is a very important characteristic of natural language generation methods. Instead of relying on human participants for scoring or labeling the text samples, we propose to automate the process by using a human likeliness metric we define and a discrimination procedure based on large pretrained language models with their probability distributions. We analyze the text probability fractions and observe how they are influenced by the size of the generative and discriminative models involved in the process. Based on our results, bigger generators and larger pretrained discriminators are more appropriate for a better evaluation of text naturalness. A comprehensive validation procedure with human participants is required as follow up to check how well this automatic evaluation scheme correlates with human judgments.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\joelw\\Zotero\\storage\\CZ44XUVH\\Çano en Bojar - 2020 - Automating Text Naturalness Evaluation of NLG Syst.pdf;C\:\\Users\\joelw\\Zotero\\storage\\L48GNXGG\\2006.html}
}

@book{cormenIntroductionAlgorithms2009,
  title = {Introduction to Algorithms},
  editor = {Cormen, Thomas H.},
  year = {2009},
  edition = {3rd ed},
  publisher = {{MIT Press}},
  address = {{Cambridge, Mass}},
  isbn = {978-0-262-03384-8 978-0-262-53305-8},
  lccn = {QA76.6 .C662 2009},
  keywords = {Computer algorithms,Computer programming},
  annotation = {OCLC: ocn311310321},
  file = {C:\Users\joelw\Zotero\storage\6AZL4S3T\Cormen_2009_Introduction to algorithms.pdf}
}

@book{descartesPhilosophicalWorksDescartes1911,
  title = {{The philosophical works of Descartes}},
  author = {Descartes, {\relax Ren{\'e}}. and Haldane, Elizabeth Sanderson and Ross, G. R. T. (George Robert Thomson)},
  year = {1911},
  publisher = {{University Press}},
  address = {{Cambridge}},
  chapter = {2 volumes : diagrams ; 23 cm},
  isbn = {978-0-521-09416-0 978-0-521-09417-7},
  langid = {Engels}
}

@misc{dusekReferencelessQualityEstimation2017,
  title = {Referenceless {{Quality Estimation}} for {{Natural Language Generation}}},
  author = {Du{\v s}ek, Ond{\v r}ej and Novikova, Jekaterina and Rieser, Verena},
  year = {2017},
  month = aug,
  number = {arXiv:1708.01759},
  eprint = {1708.01759},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1708.01759},
  urldate = {2023-11-17},
  abstract = {Traditional automatic evaluation measures for natural language generation (NLG) use costly human-authored references to estimate the quality of a system output. In this paper, we propose a referenceless quality estimation (QE) approach based on recurrent neural networks, which predicts a quality score for a NLG system output by comparing it to the source meaning representation only. Our method outperforms traditional metrics and a constant baseline in most respects; we also show that synthetic data helps to increase correlation results by 21\% compared to the base system. Our results are comparable to results obtained in similar QE tasks despite the more challenging setting.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,I.2.7},
  file = {C\:\\Users\\joelw\\Zotero\\storage\\TNLT2PZY\\Dušek e.a. - 2017 - Referenceless Quality Estimation for Natural Langu.pdf;C\:\\Users\\joelw\\Zotero\\storage\\SE27IA7Q\\1708.html}
}

@article{franklinBratmanIdentityTime2017,
  title = {Bratman on Identity over Time and Identification at a Time},
  author = {Franklin, Christopher Evan},
  year = {2017},
  month = jan,
  journal = {Philosophical Explorations},
  volume = {20},
  number = {1},
  pages = {1--14},
  publisher = {{Routledge}},
  issn = {1386-9795},
  doi = {10.1080/13869795.2016.1221120},
  urldate = {2022-04-11},
  abstract = {According to reductionists about agency, an agent's bringing something about is reducible to states and events (such as desires and beliefs) involving the agent bringing something about. Many have worried that reductionism cannot accommodate robust forms of agency, such as self-determination. One common reductionist answer to this worry (which I call ``identification reductionism'') contends that self-determining agents are identified with certain states and events, and so these states and events causing a decision counts as the agent's self-determining the decision. In this paper, I discuss Michael Bratman's well-known identification reductionist theory and his general strategy of grounding an agent's identification at a time in the agent's identity over time. I develop two constraints that an adequate identification reductionist theory must satisfy, argue that Bratman's theory cannot satisfy both, and show that his general strategy for grounding an agent's identification at a time in the agent's identity over time is without merit.},
  keywords = {Bratman,causal theory of action,identification,reductionism,self-determination},
  file = {C\:\\Users\\joelw\\Zotero\\storage\\S9A5RPDF\\Franklin_2017_Bratman on identity over time and identification at a time.pdf;C\:\\Users\\joelw\\Zotero\\storage\\EGK9AP5W\\13869795.2016.html}
}

@inproceedings{gkatziaSnapshotNLGEvaluation2015,
  title = {A {{Snapshot}} of {{NLG Evaluation Practices}} 2005 - 2014},
  booktitle = {Proceedings of the 15th {{European Workshop}} on {{Natural Language Generation}} ({{ENLG}})},
  author = {Gkatzia, Dimitra and Mahamood, Saad},
  editor = {Belz, Anya and Gatt, Albert and Portet, Fran{\c c}ois and Purver, Matthew},
  year = {2015},
  month = sep,
  pages = {57--60},
  publisher = {{Association for Computational Linguistics}},
  address = {{Brighton, UK}},
  doi = {10.18653/v1/W15-4708},
  urldate = {2023-11-16},
  file = {C:\Users\joelw\Zotero\storage\3V52E3ZS\Gkatzia en Mahamood - 2015 - A Snapshot of NLG Evaluation Practices 2005 - 2014.pdf}
}

@inproceedings{grovesTreatSystemHuman2018,
  title = {Treat the System like a Human Student: {{Automatic}} Naturalness Evaluation of Generated Text without Reference Texts},
  shorttitle = {Treat the System like a Human Student},
  booktitle = {Proceedings of the 11th {{International Conference}} on {{Natural Language Generation}}},
  author = {Groves, Isabel and Tian, Ye and Douratsos, Ioannis},
  editor = {Krahmer, Emiel and Gatt, Albert and Goudbeek, Martijn},
  year = {2018},
  month = nov,
  pages = {109--118},
  publisher = {{Association for Computational Linguistics}},
  address = {{Tilburg University, The Netherlands}},
  doi = {10.18653/v1/W18-6512},
  urldate = {2023-11-16},
  abstract = {The current most popular method for automatic Natural Language Generation (NLG) evaluation is comparing generated text with human-written reference sentences using a metrics system, which has drawbacks around reliability and scalability. We draw inspiration from second language (L2) assessment and extract a set of linguistic features to predict human judgments of sentence naturalness. Our experiment using a small dataset showed that the feature-based approach yields promising results, with the added potential of providing interpretability into the source of the problems.},
  file = {C:\Users\joelw\Zotero\storage\7E2H3V2I\Groves e.a. - 2018 - Treat the system like a human student Automatic n.pdf}
}

@misc{guptaVisualSearchAsymmetry2021,
  title = {Visual {{Search Asymmetry}}: {{Deep Nets}} and {{Humans Share Similar Inherent Biases}}},
  shorttitle = {Visual {{Search Asymmetry}}},
  author = {Gupta, Shashi Kant and Zhang, Mengmi and Wu, Chia-Chien and Wolfe, Jeremy M. and Kreiman, Gabriel},
  year = {2021},
  month = nov,
  number = {arXiv:2106.02953},
  eprint = {2106.02953},
  primaryclass = {cs, q-bio},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2106.02953},
  urldate = {2023-10-01},
  abstract = {Visual search is a ubiquitous and often challenging daily task, exemplified by looking for the car keys at home or a friend in a crowd. An intriguing property of some classical search tasks is an asymmetry such that finding a target A among distractors B can be easier than finding B among A. To elucidate the mechanisms responsible for asymmetry in visual search, we propose a computational model that takes a target and a search image as inputs and produces a sequence of eye movements until the target is found. The model integrates eccentricity-dependent visual recognition with target-dependent top-down cues. We compared the model against human behavior in six paradigmatic search tasks that show asymmetry in humans. Without prior exposure to the stimuli or task-specific training, the model provides a plausible mechanism for search asymmetry. We hypothesized that the polarity of search asymmetry arises from experience with the natural environment. We tested this hypothesis by training the model on augmented versions of ImageNet where the biases of natural images were either removed or reversed. The polarity of search asymmetry disappeared or was altered depending on the training protocol. This study highlights how classical perceptual properties can emerge in neural network models, without the need for task-specific training, but rather as a consequence of the statistical properties of the developmental diet fed to the model. All source code and data are publicly available at https://github.com/kreimanlab/VisualSearchAsymmetry.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\joelw\\Zotero\\storage\\T2GVBIK4\\Gupta e.a. - 2021 - Visual Search Asymmetry Deep Nets and Humans Shar.pdf;C\:\\Users\\joelw\\Zotero\\storage\\WN5XMJ54\\2106.html}
}

@article{lawlorTaurekNumbersProbabilities2006,
  title = {Taurek, {{Numbers}} and {{Probabilities}}},
  author = {Lawlor, Rob},
  year = {2006},
  month = apr,
  journal = {Ethical Theory and Moral Practice},
  volume = {9},
  number = {2},
  pages = {149--166},
  issn = {1572-8447},
  doi = {10.1007/s10677-005-9004-4},
  urldate = {2021-12-23},
  abstract = {In his paper, ``Should the Numbers Count?" John Taurek imagines that we are in a position such that we can either save a group of five people, or we can save one individual, David. We cannot save David and the five. This is because they each require a life-saving drug. However, David needs all of the drug if he is to survive, while the other five need only a fifth each.},
  langid = {english},
  file = {C:\Users\joelw\Zotero\storage\WA8AAKRK\Lawlor_2006_Taurek, Numbers and Probabilities.pdf}
}

@inproceedings{leePromptbasedLearningText2023,
  title = {Prompt-Based {{Learning}} for {{Text Readability Assessment}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EACL}} 2023},
  author = {Lee, Bruce W. and Lee, Jason},
  editor = {Vlachos, Andreas and Augenstein, Isabelle},
  year = {2023},
  month = may,
  pages = {1819--1824},
  publisher = {{Association for Computational Linguistics}},
  address = {{Dubrovnik, Croatia}},
  doi = {10.18653/v1/2023.findings-eacl.135},
  urldate = {2023-11-16},
  abstract = {We propose the novel adaptation of a pre-trained seq2seq model for readability assessment. We prove that a seq2seq model - T5 or BART - can be adapted to discern which text is more difficult from two given texts (pairwise). As an exploratory study to prompt-learn a neural network for text readability in a text-to-text manner, we report useful tips for future work in seq2seq training and ranking-based approach to readability assessment. Specifically, we test nine input-output formats/prefixes and show that they can significantly influence the final model performance. Also, we argue that the combination of text-to-text training and pairwise ranking setup 1) enables leveraging multiple parallel text simplification data for teaching readability and 2) trains a neural model for the general concept of readability (therefore, better cross-domain generalization). At last, we report a 99.6\% pairwise classification accuracy on Newsela and a 98.7\% for OneStopEnglish, through a joint training approach. Our code is available at github.com/brucewlee/prompt-learning-readability.},
  file = {C:\Users\joelw\Zotero\storage\DDN7LPXA\Lee en Lee - 2023 - Prompt-based Learning for Text Readability Assessm.pdf}
}

@incollection{lewisMadPainMartian1983,
  title = {Mad {{Pain}} and {{Martian Pain}}},
  booktitle = {Philosophical {{Papers Volume I}}},
  author = {Lewis, David},
  year = {1983},
  publisher = {{Oxford University Press}},
  address = {{New York}},
  doi = {10.1093/0195032047.003.0009},
  urldate = {2022-01-18},
  abstract = {Lewis invites us to consider two ostensible challenges to any materialist theory of the mind. The madman feels pain just as we do, but his pain differs greatly from ours in its characteristic causes and effects; the Martian also feels pain just as we do, but his pain differs greatly from ours in its physical realization. Lewis argues that his functionalist theory is adequate to meet the challenges presented by both cases. In the postscript, Lewis considers how advocates of phenomenal qualia respond to the functionalist account he defends; in particular, he responds to Frank Jackson's `knowledge argument'.},
  isbn = {978-0-19-503204-8},
  langid = {english},
  keywords = {Armstrong,Frank Jackson,functionalism,materialism,pain,phenomenal,qualia,type-identity}
}

@inproceedings{liuNaturalnessEvaluationNatural2021,
  title = {Naturalness {{Evaluation}} of {{Natural Language Generation}} in {{Task-oriented Dialogues Using BERT}}},
  booktitle = {Proceedings of the {{International Conference}} on {{Recent Advances}} in {{Natural Language Processing}} ({{RANLP}} 2021)},
  author = {Liu, Ye and Maier, Wolfgang and Minker, Wolfgang and Ultes, Stefan},
  editor = {Mitkov, Ruslan and Angelova, Galia},
  year = {2021},
  month = sep,
  pages = {839--845},
  publisher = {{INCOMA Ltd.}},
  address = {{Held Online}},
  urldate = {2023-11-16},
  abstract = {This paper presents an automatic method to evaluate the naturalness of natural language generation in dialogue systems. While this task was previously rendered through expensive and time-consuming human labor, we present this novel task of automatic naturalness evaluation of generated language. By fine-tuning the BERT model, our proposed naturalness evaluation method shows robust results and outperforms the baselines: support vector machines, bi-directional LSTMs, and BLEURT. In addition, the training speed and evaluation performance of naturalness model are improved by transfer learning from quality and informativeness linguistic knowledge.},
  file = {C:\Users\joelw\Zotero\storage\QCD24BEY\Liu e.a. - 2021 - Naturalness Evaluation of Natural Language Generat.pdf}
}

@book{nagelStructureScienceProblems1961,
  title = {The {{Structure}} of {{Science}}: {{Problems}} in the {{Logic}} of {{Scientific Explanation}}},
  shorttitle = {The {{Structure}} of {{Science}}},
  author = {Nagel, Ernest},
  year = {1961},
  publisher = {{New York, NY, USA: Harcourt, Brace \& World}},
  file = {C:\Users\joelw\Zotero\storage\8ZR2FJJT\NAGTSO-3.html}
}

@article{peircePsychoPy2ExperimentsBehavior2019,
  title = {{{PsychoPy2}}: {{Experiments}} in Behavior Made Easy},
  shorttitle = {{{PsychoPy2}}},
  author = {Peirce, Jonathan and Gray, Jeremy R. and Simpson, Sol and MacAskill, Michael and H{\"o}chenberger, Richard and Sogo, Hiroyuki and Kastman, Erik and Lindel{\o}v, Jonas Kristoffer},
  year = {2019},
  month = feb,
  journal = {Behavior Research Methods},
  volume = {51},
  number = {1},
  pages = {195--203},
  issn = {1554-3528},
  doi = {10.3758/s13428-018-01193-y},
  urldate = {2023-10-01},
  abstract = {PsychoPy is an application for the creation of experiments in behavioral science (psychology, neuroscience, linguistics, etc.) with precise spatial control and timing of stimuli. It now provides a choice of interface; users can write scripts in Python if they choose, while those who prefer to construct experiments graphically can use the new Builder interface. Here we describe the features that have been added over the last 10 years of its development. The most notable addition has been that Builder interface, allowing users to create studies with minimal or no programming, while also allowing the insertion of Python code for maximal flexibility. We also present some of the other new features, including further stimulus options, asynchronous time-stamped hardware polling, and better support for open science and reproducibility. Tens of thousands of users now launch PsychoPy every month, and more than 90 people have contributed to the code. We discuss the current state of the project, as well as plans for the future.},
  langid = {english},
  keywords = {Experiment,Open science,Open-source,Psychology,Reaction time,Software,Timing},
  file = {C:\Users\joelw\Zotero\storage\GTPKQEZT\Peirce e.a. - 2019 - PsychoPy2 Experiments in behavior made easy.pdf}
}

@article{rodlJointActionRecursive2015,
  title = {Joint Action and Recursive Consciousness of Consciousness},
  author = {R{\"o}dl, Sebastian},
  year = {2015},
  month = dec,
  journal = {Phenomenology and the Cognitive Sciences},
  volume = {14},
  number = {4},
  pages = {769--779},
  issn = {1572-8676},
  doi = {10.1007/s11097-015-9423-1},
  urldate = {2022-04-11},
  abstract = {In a series of essays, Bratman defines a concept, which we may call the concept of Bratmanian action by many. Our discussion of this concept, in section 1, reveals that it is not the one called to mind by the usual examples of joint action. Section 2 lays alongside it a different concept of doing something together. According to it, many are doing A together if and only if the principle of the actions in which they are doing A is a joint intention to do A, an act of intending that is theirs. It seems fitting to call this joint intentional action. In distinction to Bratmanian action by many, joint intentional action is ubiquitous in human life. This raises the question what may be the interest of Bratman's concept. Its interest can reside only in a relation it bears to the concept of joint intentional action. Section 3 discusses the suggestion that Bratmanian action by many is a precursor of joint action in human phylogenesis. This is wrong because subjects are capable of Bratmanian action only in virtue of being subjects of joint action.},
  langid = {english},
  file = {C:\Users\joelw\Zotero\storage\I53M72CE\Rödl_2015_Joint action and recursive consciousness of consciousness.pdf}
}

@book{rogersFirstCourseMachine2020,
  title = {A First Course in Machine Learning},
  author = {Rogers, Simon and Girolami, Mark},
  year = {2020},
  series = {Chapman \& {{Hall}}/{{CRC}} Machine Learning \& Pattern Recognition Series},
  edition = {Second edition, first issued in paperback},
  publisher = {{CRC Press, Taylor \& Francis Group}},
  address = {{Boca Raton London New York}},
  isbn = {978-1-4987-3848-4 978-0-367-57464-2},
  langid = {english},
  file = {C:\Users\joelw\Zotero\storage\J9RXS4AR\Rogers_Girolami_2020_A first course in machine learning.pdf}
}

@article{ryleDescartesMyth1949,
  title = {Descartes' {{Myth}}},
  author = {Ryle, Gilbert},
  editor = {Chalmers, David J.},
  year = {1949},
  journal = {Philosophy of Mind: Classical and Contemporary Readings},
  pages = {13},
  file = {C:\Users\joelw\Zotero\storage\KNKI9D3R\Ryle - 2002 - Descartes' Myth.pdf}
}

@article{sandersWhyNumbersShould1988,
  title = {Why the {{Numbers Should Sometimes Count}}},
  author = {Sanders, John T.},
  year = {1988},
  journal = {Philosophy \& Public Affairs},
  volume = {17},
  number = {1},
  eprint = {2265283},
  eprinttype = {jstor},
  pages = {3--14},
  publisher = {{Wiley}},
  issn = {0048-3915},
  urldate = {2021-12-23},
  file = {C:\Users\joelw\Zotero\storage\TLUMXD8K\Why the Numbers Should Sometimes Count - John T. Sanders.pdf}
}

@article{searleMindsBrainsPrograms1980,
  title = {Minds, Brains, and Programs},
  author = {Searle, John R.},
  year = {1980},
  journal = {Behavioral and Brain Sciences},
  volume = {3},
  number = {3},
  pages = {417--424},
  issn = {1469-1825},
  doi = {10.1017/S0140525X00005756},
  abstract = {This article can be viewed as an attempt to explore the consequences of two propositions. (1) Intentionality in human beings (and animals) is a product of causal features of the brain. I assume this is an empirical fact about the actual causal relations between mental processes and brains. It says simply that certain brain processes are sufficient for intentionality. (2) Instantiating a computer program is never by itself a sufficient condition of intentionality. The main argument of this paper is directed at establishing this claim. The form of the argument is to show how a human agent could instantiate the program and still not have the relevant intentionality. These two propositions have the following consequences: (3) The explanation of how the brain produces intentionality cannot be that it does it by instantiating a computer program. This is a strict logical consequence of 1 and 2. (4) Any mechanism capable of producing intentionality must have causal powers equal to those of the brain. This is meant to be a trivial consequence of 1. (5) Any attempt literally to create intentionality artificially (strong AI) could not succeed just by designing programs but would have to duplicate the causal powers of the human brain. This follows from 2 and 4.``Could a machine think?'' On the argument advanced here only a machine could think, and only very special kinds of machines, namely brains and machines with internal causal powers equivalent to those of brains. And that is why strong AI has little to tell us about thinking, since it is not about machines but about programs, and no program by itself is sufficient for thinking.},
  keywords = {artificial intelligence,brain,intentionality,mind},
  file = {C\:\\Users\\joelw\\Zotero\\storage\\K8466ES9\\Searle - 1980 - Minds, brains, and programs.pdf;C\:\\Users\\joelw\\Zotero\\storage\\Y8NZSJ9W\\DC644B47A4299C637C89772FACC2706A.html}
}

@article{taurekShouldNumbersCount1977,
  title = {Should the {{Numbers Count}}?},
  author = {Taurek, John M.},
  year = {1977},
  journal = {Philosophy \& Public Affairs},
  volume = {6},
  number = {4},
  eprint = {2264945},
  eprinttype = {jstor},
  pages = {293--316},
  publisher = {{Wiley}},
  issn = {0048-3915},
  urldate = {2021-12-23},
  file = {C:\Users\joelw\Zotero\storage\L5QM7MH5\Taurek_1977_Should the Numbers Count.pdf}
}

@article{thomsonTrolleyProblem1985,
  title = {The {{Trolley Problem}}},
  author = {Thomson, Judith Jarvis},
  year = {1985},
  journal = {The Yale Law Journal},
  volume = {94},
  number = {6},
  eprint = {796133},
  eprinttype = {jstor},
  pages = {1395--1415},
  publisher = {{The Yale Law Journal Company, Inc.}},
  issn = {0044-0094},
  doi = {10.2307/796133},
  urldate = {2021-12-24},
  file = {C:\Users\joelw\Zotero\storage\URM3UGKK\Thomson_1985_The Trolley Problem.pdf}
}

@article{treismanFeatureAnalysisEarly1988,
  title = {Feature Analysis in Early Vision: {{Evidence}} from Search Asymmetries.},
  author = {Treisman, Anne and Gormican, Stephen},
  year = {1988},
  journal = {Psychological Review},
  volume = {95},
  number = {1},
  pages = {15--48},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471(Electronic),0033-295X(Print)},
  doi = {10.1037/0033-295X.95.1.15},
  abstract = {A series of search experiments tested detection of targets distinguished from the distractors by differences on a single dimension. Our aim was to use the pattern of search latencies to infer which features are coded automatically in early vision. For each of 12 different dimensions, one or more pairs of contrasting stimuli were tested. Each member of a pair played the role of target in one condition and the role of distractor in the other condition. Targets defined by larger values on the quantitative dimensions of length, number, and contrast, by line curvature, by misaligned orientation, and by values that deviated from a standard or prototypical color or shape were detected easily, whereas targets defined by smaller values on the quantitative dimensions, by straightness, by frame-aligned orientation, and by prototypical colors or shapes required slow and apparently serial search. We interpret the results as evidence that focused attention to single items or to groups is required to reduce background activity when the Weber fraction distinguishing the pooled feature activity with displays containing a target and with displays containing only distractors is too small to allow reliable discrimination. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {*Color Perception,*Spatial Organization,*Visual Contrast,*Visual Discrimination,*Visual Search,Form and Shape Perception},
  file = {C:\Users\joelw\Zotero\storage\CG6JLHRN\Treisman en Gormican - 1988 - Feature analysis in early vision Evidence from se.pdf}
}

@article{wolfeRoleCategorizationVisual1992,
  title = {The Role of Categorization in Visual Search for Orientation.},
  author = {Wolfe, Jeremy M. and {Friedman-Hill}, Stacia R. and Stewart, Marion I. and O'Connell, Kathleen M.},
  year = {1992},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  volume = {18},
  number = {1},
  pages = {34--49},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1277(Electronic),0096-1523(Print)},
  doi = {10.1037/0096-1523.18.1.34},
  abstract = {Visual search for 1 target orientation is fast and virtually independent of set size if all of the distractors are of a single, different orientation. However, in the presence of distractors of several orientations, search can become inefficient and strongly dependent on set size (Exp 1). Search can be inefficient even if only 2 distractor orientations are used and even if those orientations are quite remote from the target orientation (e.g., 20\textdegree{} or even 40\textdegree{} away, Exp 2). Search for 1 orientation among heterogeneous distractor orientations becomes more efficient if the target orientation is the only item possessing a categorical attribute such as steep, shallow (Exp 3), tilted left or tilted right (Exp 4), or simply tilted (Exps 5 and 6). Orientation categories appear to be 1 of several strategies used in visual search for orientation. These serve as a compromise between the limits on parallel visual processing and the demands of a complex visual world. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {*Classification (Cognitive Process),*Spatial Organization,*Spatial Orientation (Perception),Visual Search},
  file = {C:\Users\joelw\Zotero\storage\6AQ4YKMF\Wolfe e.a. - 1992 - The role of categorization in visual search for or.pdf}
}

@inproceedings{zhuGRUENEvaluatingLinguistic2020,
  title = {{{GRUEN}} for {{Evaluating Linguistic Quality}} of {{Generated Text}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EMNLP}} 2020},
  author = {Zhu, Wanzheng and Bhat, Suma},
  editor = {Cohn, Trevor and He, Yulan and Liu, Yang},
  year = {2020},
  month = nov,
  pages = {94--108},
  publisher = {{Association for Computational Linguistics}},
  address = {{Online}},
  doi = {10.18653/v1/2020.findings-emnlp.9},
  urldate = {2023-11-16},
  abstract = {Automatic evaluation metrics are indispensable for evaluating generated text. To date, these metrics have focused almost exclusively on the content selection aspect of the system output, ignoring the linguistic quality aspect altogether. We bridge this gap by proposing GRUEN for evaluating Grammaticality, non-Redundancy, focUs, structure and coherENce of generated text. GRUEN utilizes a BERT-based model and a class of syntactic, semantic, and contextual features to examine the system output. Unlike most existing evaluation metrics which require human references as an input, GRUEN is reference-less and requires only the system output. Besides, it has the advantage of being unsupervised, deterministic, and adaptable to various tasks. Experiments on seven datasets over four language generation tasks show that the proposed metric correlates highly with human judgments.},
  file = {C:\Users\joelw\Zotero\storage\BUE8AG85\Zhu en Bhat - 2020 - GRUEN for Evaluating Linguistic Quality of Generat.pdf}
}
